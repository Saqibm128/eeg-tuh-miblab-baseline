{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction for Shallow Learners\n",
    "## TSFresh Feature Extraction\n",
    "see: https://docs.google.com/presentation/d/1QQYKjV47gLrgohGNP-5UQj67KMwFzrrGEGJyi-y2Ox0/edit#slide=id.g6c263ea923_0_896 slides 51-58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'datasets' from '/home/mohammed/eeg-miblab/datasets.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import datasets\n",
    "from importlib import reload\n",
    "reload(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/miniconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:1: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/mohammed/miniconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:2: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "testFile = h5py.File(\"/datadrive/TUH_EEG/MUPS/data/cross_sub_TUH_EEG_denoised/cross_subject_data_test.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_edss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features\n",
    "def extract(eeg):\n",
    "    eeg = pd.DataFrame(eeg)\n",
    "    return extract_features(eeg.unstack().reset_index()[[\"level_0\", 0]], column_id=\"level_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/46446 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 24/46446 [00:19<19:04, 40.56it/s]\u001b[A\n",
      "  0%|          | 12/46446 [00:18<10:08, 76.26it/s]\u001b[A\n",
      "  0%|          | 24/46446 [01:38<31:54:26,  2.47s/it]\u001b[A\n",
      "  0%|          | 36/46446 [03:17<54:08:25,  4.20s/it]\u001b[A\n",
      "  0%|          | 48/46446 [04:56<69:39:07,  5.40s/it]\u001b[A\n",
      "  0%|          | 60/46446 [06:35<80:38:02,  6.26s/it]\u001b[A\n",
      "  0%|          | 72/46446 [08:13<88:16:46,  6.85s/it]\u001b[A\n",
      "  0%|          | 84/46446 [09:53<93:45:27,  7.28s/it]\u001b[A\n",
      "  0%|          | 96/46446 [11:32<97:31:01,  7.57s/it]\u001b[A\n",
      "  0%|          | 108/46446 [13:12<100:20:01,  7.79s/it]\u001b[A\n",
      "  0%|          | 120/46446 [14:52<102:29:40,  7.96s/it]\u001b[A\n",
      "  0%|          | 132/46446 [16:32<103:45:23,  8.07s/it]\u001b[A\n",
      "  0%|          | 144/46446 [18:12<104:46:03,  8.15s/it]\u001b[A\n",
      "  0%|          | 156/46446 [19:51<105:13:52,  8.18s/it]\u001b[A\n",
      "  0%|          | 168/46446 [21:31<105:55:26,  8.24s/it]\u001b[A\n",
      "  0%|          | 180/46446 [23:11<106:05:44,  8.26s/it]\u001b[A\n",
      "  0%|          | 192/46446 [24:50<106:06:11,  8.26s/it]\u001b[A\n",
      "  0%|          | 204/46446 [26:29<106:02:16,  8.26s/it]\u001b[A\n",
      "  0%|          | 216/46446 [28:07<105:46:22,  8.24s/it]\u001b[A\n",
      "  0%|          | 228/46446 [29:46<105:45:33,  8.24s/it]\u001b[A\n",
      "  1%|          | 240/46446 [31:26<105:53:58,  8.25s/it]\u001b[A\n",
      "  1%|          | 252/46446 [33:05<105:55:45,  8.26s/it]\u001b[A\n",
      "  1%|          | 264/46446 [34:44<105:59:02,  8.26s/it]\u001b[A\n",
      "  1%|          | 276/46446 [36:24<106:19:05,  8.29s/it]\u001b[A\n",
      "  1%|          | 288/46446 [38:04<106:18:50,  8.29s/it]\u001b[A\n",
      "  1%|          | 300/46446 [39:43<106:18:02,  8.29s/it]\u001b[A\n",
      "  1%|          | 312/46446 [41:23<106:18:54,  8.30s/it]\u001b[A\n",
      "  1%|          | 324/46446 [43:02<106:08:52,  8.29s/it]\u001b[A\n",
      "  1%|          | 336/46446 [44:42<106:23:55,  8.31s/it]\u001b[A\n",
      "  1%|          | 348/46446 [46:22<106:25:38,  8.31s/it]\u001b[A\n",
      "  1%|          | 360/46446 [48:02<106:17:20,  8.30s/it]\u001b[A\n",
      "  1%|          | 372/46446 [49:41<106:05:29,  8.29s/it]\u001b[A\n",
      "  1%|          | 384/46446 [51:20<106:00:30,  8.29s/it]\u001b[A\n",
      "  1%|          | 396/46446 [52:58<105:35:19,  8.25s/it]\u001b[A\n",
      "  1%|          | 408/46446 [54:35<104:52:54,  8.20s/it]\u001b[A\n",
      "  1%|          | 420/46446 [56:13<104:46:01,  8.19s/it]\u001b[A\n",
      "  1%|          | 432/46446 [57:58<106:46:04,  8.35s/it]\u001b[A\n",
      "  1%|          | 444/46446 [59:35<105:45:02,  8.28s/it]\u001b[A\n",
      "  1%|          | 456/46446 [1:01:20<107:25:36,  8.41s/it]\u001b[A\n",
      "  1%|          | 468/46446 [1:02:58<106:34:38,  8.34s/it]\u001b[A\n",
      "  1%|          | 480/46446 [1:04:38<106:20:01,  8.33s/it]\u001b[A\n",
      "  1%|          | 492/46446 [1:06:22<107:37:10,  8.43s/it]\u001b[A\n",
      "  1%|          | 504/46446 [1:08:02<107:23:31,  8.42s/it]\u001b[A\n",
      "  1%|          | 516/46446 [1:09:43<107:21:54,  8.42s/it]\u001b[A\n",
      "  1%|          | 528/46446 [1:11:24<107:15:24,  8.41s/it]\u001b[A\n",
      "  1%|          | 540/46446 [1:13:05<107:18:27,  8.42s/it]\u001b[A\n",
      "  1%|          | 552/46446 [1:14:47<107:26:28,  8.43s/it]\u001b[A\n",
      "  1%|          | 564/46446 [1:16:26<106:53:41,  8.39s/it]\u001b[A\n",
      "  1%|          | 576/46446 [1:18:07<106:51:05,  8.39s/it]\u001b[A\n",
      "  1%|▏         | 588/46446 [1:19:46<106:27:48,  8.36s/it]\u001b[A\n",
      "  1%|▏         | 600/46446 [1:21:26<106:17:17,  8.35s/it]\u001b[A\n",
      "  1%|▏         | 612/46446 [1:23:05<105:57:26,  8.32s/it]\u001b[A\n",
      "  1%|▏         | 624/46446 [1:24:45<105:44:44,  8.31s/it]\u001b[A\n",
      "  1%|▏         | 636/46446 [1:26:24<105:45:16,  8.31s/it]\u001b[A\n",
      "  1%|▏         | 648/46446 [1:28:03<105:31:39,  8.30s/it]\u001b[A\n",
      "  1%|▏         | 660/46446 [1:29:43<105:26:19,  8.29s/it]\u001b[A\n",
      "  1%|▏         | 672/46446 [1:31:22<105:24:10,  8.29s/it]\u001b[A\n",
      "  1%|▏         | 684/46446 [1:33:02<105:32:37,  8.30s/it]\u001b[A\n",
      "  1%|▏         | 696/46446 [1:34:42<105:30:43,  8.30s/it]\u001b[A\n",
      "  2%|▏         | 708/46446 [1:36:22<105:45:39,  8.32s/it]\u001b[A\n",
      "  2%|▏         | 720/46446 [1:38:02<105:44:29,  8.33s/it]\u001b[A\n",
      "  2%|▏         | 732/46446 [1:39:42<105:38:30,  8.32s/it]\u001b[A\n",
      "  2%|▏         | 744/46446 [1:41:21<105:28:56,  8.31s/it]\u001b[A\n",
      "  2%|▏         | 756/46446 [1:43:01<105:17:17,  8.30s/it]\u001b[A\n",
      "  2%|▏         | 768/46446 [1:44:41<105:28:18,  8.31s/it]\u001b[A\n",
      "  2%|▏         | 780/46446 [1:46:20<105:25:59,  8.31s/it]\u001b[A\n",
      "  2%|▏         | 792/46446 [1:48:00<105:18:08,  8.30s/it]\u001b[A\n",
      "  2%|▏         | 804/46446 [1:49:39<105:13:21,  8.30s/it]\u001b[A\n",
      "  2%|▏         | 816/46446 [1:51:19<105:09:49,  8.30s/it]\u001b[A\n",
      "  2%|▏         | 828/46446 [1:52:58<104:58:29,  8.28s/it]\u001b[A\n",
      "  2%|▏         | 840/46446 [1:54:37<104:48:35,  8.27s/it]\u001b[A\n",
      "  2%|▏         | 852/46446 [1:56:16<104:37:05,  8.26s/it]\u001b[A\n",
      "  2%|▏         | 864/46446 [1:57:55<104:33:52,  8.26s/it]\u001b[A\n",
      "  2%|▏         | 876/46446 [1:59:35<104:47:45,  8.28s/it]\u001b[A\n",
      "  2%|▏         | 888/46446 [2:01:15<105:12:55,  8.31s/it]\u001b[A\n",
      "  2%|▏         | 900/46446 [2:02:55<105:00:12,  8.30s/it]\u001b[A\n",
      "  2%|▏         | 912/46446 [2:04:34<104:53:57,  8.29s/it]\u001b[A\n",
      "  2%|▏         | 924/46446 [2:06:13<104:51:33,  8.29s/it]\u001b[A\n",
      "  2%|▏         | 936/46446 [2:07:52<104:38:41,  8.28s/it]\u001b[A\n",
      "  2%|▏         | 948/46446 [2:09:32<104:35:39,  8.28s/it]\u001b[A\n",
      "  2%|▏         | 960/46446 [2:11:12<104:45:34,  8.29s/it]\u001b[A\n",
      "  2%|▏         | 972/46446 [2:12:52<104:56:33,  8.31s/it]\u001b[A\n",
      "  2%|▏         | 984/46446 [2:14:32<105:13:36,  8.33s/it]\u001b[A\n",
      "  2%|▏         | 996/46446 [2:16:11<104:55:41,  8.31s/it]\u001b[A\n",
      "  2%|▏         | 1008/46446 [2:17:51<104:51:07,  8.31s/it]\u001b[A\n",
      "  2%|▏         | 1020/46446 [2:19:30<104:38:05,  8.29s/it]\u001b[A\n",
      "  2%|▏         | 1032/46446 [2:21:10<104:38:10,  8.29s/it]\u001b[A\n",
      "  2%|▏         | 1044/46446 [2:22:49<104:40:24,  8.30s/it]\u001b[A\n",
      "  2%|▏         | 1056/46446 [2:24:29<104:36:56,  8.30s/it]\u001b[A\n",
      "  2%|▏         | 1068/46446 [2:26:09<104:44:41,  8.31s/it]\u001b[A\n",
      "  2%|▏         | 1080/46446 [2:27:48<104:37:06,  8.30s/it]\u001b[A\n",
      "  2%|▏         | 1092/46446 [2:29:28<104:25:20,  8.29s/it]\u001b[A\n",
      "  2%|▏         | 1104/46446 [2:31:09<105:00:31,  8.34s/it]\u001b[A\n",
      "  2%|▏         | 1116/46446 [2:32:50<105:15:28,  8.36s/it]\u001b[A\n",
      "  2%|▏         | 1128/46446 [2:34:31<105:35:58,  8.39s/it]\u001b[A\n",
      "  2%|▏         | 1140/46446 [2:35:25<90:44:32,  7.21s/it] \u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-10a6a7b228dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meeg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meeg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    538\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "all_dfs = Parallel(n_jobs=12)(delayed(extract)(eeg) for eeg in tqdm(train_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simpler feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting simple handEngineeredData\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/miniconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:8: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 12 processes\n",
      "retrieving: 0\n",
      "retrieving: 250\n",
      "retrieving: 500\n",
      "retrieving: 750\n",
      "retrieving: 1000\n",
      "retrieving: 1250\n",
      "retrieving: 1500\n",
      "retrieving: 1750\n",
      "retrieving: 2000\n",
      "retrieving: 2250\n",
      "retrieving: 2500\n",
      "retrieving: 2750\n",
      "retrieving: 3000\n",
      "retrieving: 3250\n",
      "retrieving: 3500\n",
      "retrieving: 3750\n",
      "retrieving: 4000\n",
      "retrieving: 4250\n",
      "retrieving: 4500\n",
      "retrieving: 4750\n",
      "retrieving: 5000\n",
      "retrieving: 5250\n",
      "retrieving: 5500\n",
      "retrieving: 5750\n",
      "retrieving: 6000\n",
      "retrieving: 6250\n",
      "retrieving: 6500\n",
      "retrieving: 6750\n",
      "retrieving: 7000\n",
      "retrieving: 7250\n",
      "retrieving: 7500\n",
      "retrieving: 7750\n",
      "retrieving: 8000\n",
      "retrieving: 8250\n",
      "retrieving: 8500\n",
      "retrieving: 8750\n",
      "retrieving: 9000\n",
      "retrieving: 9250\n",
      "retrieving: 9500\n",
      "retrieving: 9750\n",
      "retrieving: 10000\n",
      "retrieving: 10250\n",
      "retrieving: 10500\n",
      "retrieving: 10750\n",
      "retrieving: 11000\n",
      "retrieving: 11250\n",
      "retrieving: 11500\n",
      "retrieving: 11750\n",
      "retrieving: 12000\n",
      "retrieving: 12250\n",
      "retrieving: 12500\n",
      "retrieving: 12750\n",
      "retrieving: 13000\n",
      "retrieving: 13250\n",
      "retrieving: 13500\n",
      "retrieving: 13750\n",
      "retrieving: 14000\n",
      "retrieving: 14250\n",
      "retrieving: 14500\n",
      "retrieving: 14750\n",
      "retrieving: 15000\n",
      "retrieving: 15250\n",
      "retrieving: 15500\n",
      "retrieving: 15750\n",
      "retrieving: 16000\n",
      "retrieving: 16250\n",
      "retrieving: 16500\n",
      "retrieving: 16750\n",
      "retrieving: 17000\n",
      "retrieving: 17250\n",
      "retrieving: 17500\n",
      "retrieving: 17750\n",
      "retrieving: 18000\n",
      "retrieving: 18250\n",
      "retrieving: 18500\n",
      "retrieving: 18750\n",
      "retrieving: 19000\n",
      "retrieving: 19250\n",
      "retrieving: 19500\n",
      "retrieving: 19750\n",
      "retrieving: 20000\n",
      "retrieving: 20250\n",
      "retrieving: 20500\n",
      "retrieving: 20750\n",
      "retrieving: 21000\n",
      "retrieving: 21250\n",
      "retrieving: 21500\n",
      "retrieving: 21750\n",
      "retrieving: 22000\n",
      "retrieving: 22250\n",
      "retrieving: 22500\n",
      "retrieving: 22750\n",
      "retrieving: 23000\n",
      "retrieving: 23250\n",
      "retrieving: 23500\n",
      "retrieving: 23750\n",
      "retrieving: 24000\n",
      "retrieving: 24250\n",
      "retrieving: 24500\n",
      "retrieving: 24750\n",
      "retrieving: 25000\n",
      "retrieving: 25250\n",
      "retrieving: 25500\n",
      "retrieving: 25750\n",
      "retrieving: 26000\n",
      "retrieving: 26250\n",
      "retrieving: 26500\n",
      "retrieving: 26750\n",
      "retrieving: 27000\n",
      "retrieving: 27250\n",
      "retrieving: 27500\n",
      "retrieving: 27750\n",
      "retrieving: 28000\n",
      "retrieving: 28250\n",
      "retrieving: 28500\n",
      "retrieving: 28750\n",
      "retrieving: 29000\n",
      "retrieving: 29250\n",
      "retrieving: 29500\n",
      "retrieving: 29750\n",
      "retrieving: 30000\n",
      "retrieving: 30250\n",
      "retrieving: 30500\n",
      "retrieving: 30750\n",
      "retrieving: 31000\n",
      "retrieving: 31250\n",
      "retrieving: 31500\n",
      "retrieving: 31750\n",
      "retrieving: 32000\n",
      "retrieving: 32250\n",
      "retrieving: 32500\n",
      "retrieving: 32750\n",
      "retrieving: 33000\n",
      "retrieving: 33250\n",
      "retrieving: 33500\n",
      "retrieving: 33750\n",
      "retrieving: 34000\n",
      "retrieving: 34250\n",
      "retrieving: 34500\n",
      "retrieving: 34750\n",
      "retrieving: 35000\n",
      "retrieving: 35250\n",
      "retrieving: 35500\n",
      "retrieving: 35750\n",
      "retrieving: 36000\n",
      "retrieving: 36250\n",
      "retrieving: 36500\n",
      "retrieving: 36750\n",
      "retrieving: 37000\n",
      "retrieving: 37250\n",
      "retrieving: 37500\n",
      "retrieving: 37750\n",
      "retrieving: 38000\n",
      "retrieving: 38250\n",
      "retrieving: 38500\n",
      "retrieving: 38750\n",
      "retrieving: 39000\n",
      "retrieving: 39250\n",
      "retrieving: 39500\n",
      "retrieving: 39750\n",
      "retrieving: 40000\n",
      "retrieving: 40250\n",
      "retrieving: 40500\n",
      "retrieving: 40750\n",
      "retrieving: 41000\n",
      "retrieving: 41250\n",
      "retrieving: 41500\n",
      "retrieving: 41750\n",
      "retrieving: 42000\n",
      "retrieving: 42250\n",
      "retrieving: 42500\n",
      "retrieving: 42750\n",
      "retrieving: 43000\n",
      "retrieving: 43250\n",
      "retrieving: 43500\n",
      "retrieving: 43750\n",
      "retrieving: 44000\n",
      "retrieving: 44250\n",
      "retrieving: 44500\n",
      "retrieving: 44750\n",
      "retrieving: 45000\n",
      "retrieving: 45250\n",
      "retrieving: 45500\n",
      "retrieving: 45750\n",
      "retrieving: 46000\n",
      "retrieving: 46250\n",
      "Starting 12 processes\n",
      "retrieving: 0\n",
      "retrieving: 250\n",
      "retrieving: 500\n",
      "retrieving: 750\n",
      "retrieving: 1000\n",
      "retrieving: 1250\n",
      "retrieving: 1500\n",
      "retrieving: 1750\n",
      "retrieving: 2000\n",
      "retrieving: 2250\n",
      "retrieving: 2500\n",
      "retrieving: 2750\n",
      "retrieving: 3000\n",
      "retrieving: 3250\n",
      "retrieving: 3500\n",
      "retrieving: 3750\n",
      "retrieving: 4000\n",
      "retrieving: 4250\n",
      "retrieving: 4500\n",
      "retrieving: 4750\n",
      "retrieving: 5000\n",
      "retrieving: 5250\n",
      "retrieving: 5500\n",
      "retrieving: 5750\n",
      "retrieving: 6000\n",
      "retrieving: 6250\n",
      "retrieving: 6500\n",
      "retrieving: 6750\n",
      "retrieving: 7000\n",
      "retrieving: 7250\n",
      "retrieving: 7500\n",
      "retrieving: 7750\n",
      "retrieving: 8000\n",
      "retrieving: 8250\n",
      "retrieving: 8500\n",
      "retrieving: 8750\n",
      "retrieving: 9000\n",
      "retrieving: 9250\n",
      "retrieving: 9500\n",
      "retrieving: 9750\n",
      "retrieving: 10000\n",
      "retrieving: 10250\n",
      "retrieving: 10500\n",
      "retrieving: 10750\n",
      "retrieving: 11000\n",
      "retrieving: 11250\n",
      "retrieving: 11500\n",
      "retrieving: 11750\n",
      "retrieving: 12000\n",
      "retrieving: 12250\n",
      "retrieving: 12500\n",
      "retrieving: 12750\n",
      "retrieving: 13000\n",
      "retrieving: 13250\n",
      "retrieving: 13500\n",
      "retrieving: 13750\n",
      "retrieving: 14000\n",
      "retrieving: 14250\n",
      "retrieving: 14500\n",
      "retrieving: 14750\n",
      "retrieving: 15000\n",
      "retrieving: 15250\n",
      "retrieving: 15500\n",
      "retrieving: 15750\n",
      "retrieving: 16000\n",
      "retrieving: 16250\n",
      "retrieving: 16500\n",
      "retrieving: 16750\n",
      "retrieving: 17000\n",
      "retrieving: 17250\n",
      "retrieving: 17500\n",
      "retrieving: 17750\n",
      "retrieving: 18000\n",
      "retrieving: 18250\n",
      "retrieving: 18500\n",
      "retrieving: 18750\n",
      "retrieving: 19000\n",
      "retrieving: 19250\n",
      "retrieving: 19500\n",
      "retrieving: 19750\n",
      "retrieving: 20000\n",
      "retrieving: 20250\n",
      "retrieving: 20500\n",
      "retrieving: 20750\n",
      "retrieving: 21000\n",
      "retrieving: 21250\n",
      "retrieving: 21500\n",
      "retrieving: 21750\n",
      "retrieving: 22000\n",
      "retrieving: 22250\n",
      "retrieving: 22500\n",
      "retrieving: 22750\n",
      "retrieving: 23000\n",
      "retrieving: 23250\n",
      "retrieving: 23500\n",
      "retrieving: 23750\n",
      "retrieving: 24000\n",
      "retrieving: 24250\n",
      "retrieving: 24500\n",
      "retrieving: 24750\n",
      "retrieving: 25000\n",
      "retrieving: 25250\n",
      "retrieving: 25500\n",
      "retrieving: 25750\n",
      "retrieving: 26000\n",
      "retrieving: 26250\n",
      "retrieving: 26500\n",
      "retrieving: 26750\n",
      "retrieving: 27000\n",
      "retrieving: 27250\n",
      "retrieving: 27500\n",
      "retrieving: 27750\n",
      "retrieving: 28000\n",
      "retrieving: 28250\n",
      "retrieving: 28500\n",
      "retrieving: 28750\n",
      "retrieving: 29000\n",
      "retrieving: 29250\n",
      "retrieving: 29500\n",
      "retrieving: 29750\n",
      "retrieving: 30000\n",
      "retrieving: 30250\n",
      "retrieving: 30500\n",
      "retrieving: 30750\n",
      "retrieving: 31000\n",
      "retrieving: 31250\n",
      "retrieving: 31500\n",
      "retrieving: 31750\n",
      "retrieving: 32000\n",
      "retrieving: 32250\n",
      "retrieving: 32500\n",
      "retrieving: 32750\n",
      "retrieving: 33000\n",
      "retrieving: 33250\n",
      "retrieving: 33500\n",
      "retrieving: 33750\n",
      "retrieving: 34000\n",
      "retrieving: 34250\n",
      "retrieving: 34500\n",
      "retrieving: 34750\n",
      "retrieving: 35000\n",
      "retrieving: 35250\n",
      "retrieving: 35500\n",
      "retrieving: 35750\n",
      "retrieving: 36000\n",
      "retrieving: 36250\n",
      "retrieving: 36500\n",
      "retrieving: 36750\n",
      "retrieving: 37000\n",
      "retrieving: 37250\n",
      "retrieving: 37500\n",
      "retrieving: 37750\n",
      "retrieving: 38000\n",
      "retrieving: 38250\n",
      "retrieving: 38500\n",
      "retrieving: 38750\n",
      "retrieving: 39000\n",
      "retrieving: 39250\n",
      "retrieving: 39500\n",
      "retrieving: 39750\n",
      "retrieving: 40000\n",
      "retrieving: 40250\n",
      "retrieving: 40500\n",
      "retrieving: 40750\n",
      "retrieving: 41000\n",
      "retrieving: 41250\n",
      "retrieving: 41500\n",
      "retrieving: 41750\n",
      "retrieving: 42000\n",
      "retrieving: 42250\n",
      "retrieving: 42500\n",
      "retrieving: 42750\n",
      "retrieving: 43000\n",
      "retrieving: 43250\n",
      "retrieving: 43500\n",
      "retrieving: 43750\n",
      "retrieving: 44000\n",
      "retrieving: 44250\n",
      "retrieving: 44500\n",
      "retrieving: 44750\n",
      "retrieving: 45000\n",
      "retrieving: 45250\n",
      "retrieving: 45500\n",
      "retrieving: 45750\n",
      "retrieving: 46000\n",
      "retrieving: 46250\n",
      "starting simple handEngineeredData\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/miniconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:16: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 12 processes\n",
      "retrieving: 0\n",
      "retrieving: 250\n",
      "retrieving: 500\n",
      "retrieving: 750\n",
      "retrieving: 1000\n",
      "retrieving: 1250\n",
      "retrieving: 1500\n",
      "retrieving: 1750\n",
      "retrieving: 2000\n",
      "retrieving: 2250\n",
      "retrieving: 2500\n",
      "retrieving: 2750\n",
      "retrieving: 3000\n",
      "retrieving: 3250\n",
      "retrieving: 3500\n",
      "retrieving: 3750\n",
      "retrieving: 4000\n",
      "retrieving: 4250\n",
      "retrieving: 4500\n",
      "retrieving: 4750\n",
      "retrieving: 5000\n",
      "retrieving: 5250\n",
      "retrieving: 5500\n",
      "retrieving: 5750\n",
      "retrieving: 6000\n",
      "retrieving: 6250\n",
      "retrieving: 6500\n",
      "retrieving: 6750\n",
      "retrieving: 7000\n",
      "retrieving: 7250\n",
      "retrieving: 7500\n",
      "retrieving: 7750\n",
      "retrieving: 8000\n",
      "retrieving: 8250\n",
      "retrieving: 8500\n",
      "retrieving: 8750\n",
      "retrieving: 9000\n",
      "retrieving: 9250\n",
      "retrieving: 9500\n",
      "retrieving: 9750\n",
      "retrieving: 10000\n",
      "retrieving: 10250\n",
      "retrieving: 10500\n",
      "retrieving: 10750\n",
      "retrieving: 11000\n",
      "retrieving: 11250\n",
      "retrieving: 11500\n",
      "retrieving: 11750\n",
      "retrieving: 12000\n",
      "retrieving: 12250\n",
      "retrieving: 12500\n",
      "retrieving: 12750\n",
      "retrieving: 13000\n",
      "retrieving: 13250\n",
      "retrieving: 13500\n",
      "retrieving: 13750\n",
      "retrieving: 14000\n",
      "retrieving: 14250\n",
      "retrieving: 14500\n",
      "retrieving: 14750\n",
      "retrieving: 15000\n",
      "retrieving: 15250\n",
      "retrieving: 15500\n",
      "Starting 12 processes\n",
      "retrieving: 0\n",
      "retrieving: 250\n",
      "retrieving: 500\n",
      "retrieving: 750\n",
      "retrieving: 1000\n",
      "retrieving: 1250\n",
      "retrieving: 1500\n",
      "retrieving: 1750\n",
      "retrieving: 2000\n",
      "retrieving: 2250\n",
      "retrieving: 2500\n",
      "retrieving: 2750\n",
      "retrieving: 3000\n",
      "retrieving: 3250\n",
      "retrieving: 3500\n",
      "retrieving: 3750\n",
      "retrieving: 4000\n",
      "retrieving: 4250\n",
      "retrieving: 4500\n",
      "retrieving: 4750\n",
      "retrieving: 5000\n",
      "retrieving: 5250\n",
      "retrieving: 5500\n",
      "retrieving: 5750\n",
      "retrieving: 6000\n",
      "retrieving: 6250\n",
      "retrieving: 6500\n",
      "retrieving: 6750\n",
      "retrieving: 7000\n",
      "retrieving: 7250\n",
      "retrieving: 7500\n",
      "retrieving: 7750\n",
      "retrieving: 8000\n",
      "retrieving: 8250\n",
      "retrieving: 8500\n",
      "retrieving: 8750\n",
      "retrieving: 9000\n",
      "retrieving: 9250\n",
      "retrieving: 9500\n",
      "retrieving: 9750\n",
      "retrieving: 10000\n",
      "retrieving: 10250\n",
      "retrieving: 10500\n",
      "retrieving: 10750\n",
      "retrieving: 11000\n",
      "retrieving: 11250\n",
      "retrieving: 11500\n",
      "retrieving: 11750\n",
      "retrieving: 12000\n",
      "retrieving: 12250\n",
      "retrieving: 12500\n",
      "retrieving: 12750\n",
      "retrieving: 13000\n",
      "retrieving: 13250\n",
      "retrieving: 13500\n",
      "retrieving: 13750\n",
      "retrieving: 14000\n",
      "retrieving: 14250\n",
      "retrieving: 14500\n",
      "retrieving: 14750\n",
      "retrieving: 15000\n",
      "retrieving: 15250\n",
      "retrieving: 15500\n",
      "starting simple handEngineeredData\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohammed/miniconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:24: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 12 processes\n",
      "retrieving: 0\n",
      "retrieving: 250\n",
      "retrieving: 500\n",
      "retrieving: 750\n",
      "retrieving: 1000\n",
      "retrieving: 1250\n",
      "retrieving: 1500\n",
      "retrieving: 1750\n",
      "retrieving: 2000\n",
      "retrieving: 2250\n",
      "retrieving: 2500\n",
      "retrieving: 2750\n",
      "retrieving: 3000\n",
      "retrieving: 3250\n",
      "retrieving: 3500\n",
      "retrieving: 3750\n",
      "retrieving: 4000\n",
      "retrieving: 4250\n",
      "retrieving: 4500\n",
      "retrieving: 4750\n",
      "retrieving: 5000\n",
      "retrieving: 5250\n",
      "retrieving: 5500\n",
      "retrieving: 5750\n",
      "retrieving: 6000\n",
      "retrieving: 6250\n",
      "retrieving: 6500\n",
      "retrieving: 6750\n",
      "retrieving: 7000\n",
      "retrieving: 7250\n",
      "retrieving: 7500\n",
      "retrieving: 7750\n",
      "retrieving: 8000\n",
      "retrieving: 8250\n",
      "retrieving: 8500\n",
      "retrieving: 8750\n",
      "retrieving: 9000\n",
      "retrieving: 9250\n",
      "retrieving: 9500\n",
      "retrieving: 9750\n",
      "retrieving: 10000\n",
      "retrieving: 10250\n",
      "retrieving: 10500\n",
      "retrieving: 10750\n",
      "retrieving: 11000\n",
      "retrieving: 11250\n",
      "retrieving: 11500\n",
      "retrieving: 11750\n",
      "retrieving: 12000\n",
      "retrieving: 12250\n",
      "retrieving: 12500\n",
      "retrieving: 12750\n",
      "retrieving: 13000\n",
      "retrieving: 13250\n",
      "retrieving: 13500\n",
      "retrieving: 13750\n",
      "retrieving: 14000\n",
      "retrieving: 14250\n",
      "retrieving: 14500\n",
      "retrieving: 14750\n",
      "retrieving: 15000\n",
      "retrieving: 15250\n",
      "retrieving: 15500\n",
      "retrieving: 15750\n",
      "retrieving: 16000\n",
      "retrieving: 16250\n",
      "retrieving: 16500\n",
      "retrieving: 16750\n",
      "retrieving: 17000\n",
      "retrieving: 17250\n",
      "retrieving: 17500\n",
      "retrieving: 17750\n",
      "retrieving: 18000\n",
      "retrieving: 18250\n",
      "retrieving: 18500\n",
      "retrieving: 18750\n",
      "retrieving: 19000\n",
      "retrieving: 19250\n",
      "retrieving: 19500\n",
      "retrieving: 19750\n",
      "retrieving: 20000\n",
      "retrieving: 20250\n",
      "retrieving: 20500\n",
      "retrieving: 20750\n",
      "retrieving: 21000\n",
      "retrieving: 21250\n",
      "retrieving: 21500\n",
      "retrieving: 21750\n",
      "retrieving: 22000\n",
      "retrieving: 22250\n",
      "retrieving: 22500\n",
      "retrieving: 22750\n",
      "retrieving: 23000\n",
      "retrieving: 23250\n",
      "retrieving: 23500\n",
      "retrieving: 23750\n",
      "retrieving: 24000\n",
      "retrieving: 24250\n",
      "retrieving: 24500\n",
      "retrieving: 24750\n",
      "retrieving: 25000\n",
      "retrieving: 25250\n",
      "Starting 12 processes\n",
      "retrieving: 0\n",
      "retrieving: 250\n",
      "retrieving: 500\n",
      "retrieving: 750\n",
      "retrieving: 1000\n",
      "retrieving: 1250\n",
      "retrieving: 1500\n",
      "retrieving: 1750\n",
      "retrieving: 2000\n",
      "retrieving: 2250\n",
      "retrieving: 2500\n",
      "retrieving: 2750\n",
      "retrieving: 3000\n",
      "retrieving: 3250\n",
      "retrieving: 3500\n",
      "retrieving: 3750\n",
      "retrieving: 4000\n",
      "retrieving: 4250\n",
      "retrieving: 4500\n",
      "retrieving: 4750\n",
      "retrieving: 5000\n",
      "retrieving: 5250\n",
      "retrieving: 5500\n",
      "retrieving: 5750\n",
      "retrieving: 6000\n",
      "retrieving: 6250\n",
      "retrieving: 6500\n",
      "retrieving: 6750\n",
      "retrieving: 7000\n",
      "retrieving: 7250\n",
      "retrieving: 7500\n",
      "retrieving: 7750\n",
      "retrieving: 8000\n",
      "retrieving: 8250\n",
      "retrieving: 8500\n",
      "retrieving: 8750\n",
      "retrieving: 9000\n",
      "retrieving: 9250\n",
      "retrieving: 9500\n",
      "retrieving: 9750\n",
      "retrieving: 10000\n",
      "retrieving: 10250\n",
      "retrieving: 10500\n",
      "retrieving: 10750\n",
      "retrieving: 11000\n",
      "retrieving: 11250\n",
      "retrieving: 11500\n",
      "retrieving: 11750\n",
      "retrieving: 12000\n",
      "retrieving: 12250\n",
      "retrieving: 12500\n",
      "retrieving: 12750\n",
      "retrieving: 13000\n",
      "retrieving: 13250\n",
      "retrieving: 13500\n",
      "retrieving: 13750\n",
      "retrieving: 14000\n",
      "retrieving: 14250\n",
      "retrieving: 14500\n",
      "retrieving: 14750\n",
      "retrieving: 15000\n",
      "retrieving: 15250\n",
      "retrieving: 15500\n",
      "retrieving: 15750\n",
      "retrieving: 16000\n",
      "retrieving: 16250\n",
      "retrieving: 16500\n",
      "retrieving: 16750\n",
      "retrieving: 17000\n",
      "retrieving: 17250\n",
      "retrieving: 17500\n",
      "retrieving: 17750\n",
      "retrieving: 18000\n",
      "retrieving: 18250\n",
      "retrieving: 18500\n",
      "retrieving: 18750\n",
      "retrieving: 19000\n",
      "retrieving: 19250\n",
      "retrieving: 19500\n",
      "retrieving: 19750\n",
      "retrieving: 20000\n",
      "retrieving: 20250\n",
      "retrieving: 20500\n",
      "retrieving: 20750\n",
      "retrieving: 21000\n",
      "retrieving: 21250\n",
      "retrieving: 21500\n",
      "retrieving: 21750\n",
      "retrieving: 22000\n",
      "retrieving: 22250\n",
      "retrieving: 22500\n",
      "retrieving: 22750\n",
      "retrieving: 23000\n",
      "retrieving: 23250\n",
      "retrieving: 23500\n",
      "retrieving: 23750\n",
      "retrieving: 24000\n",
      "retrieving: 24250\n",
      "retrieving: 24500\n",
      "retrieving: 24750\n",
      "retrieving: 25000\n",
      "retrieving: 25250\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import constants\n",
    "import tsfresh.feature_extraction.feature_calculators as tsf\n",
    "import pickle as pkl\n",
    "reload(datasets)\n",
    "freq_bins=[0,3.5,7.5,14,20,25,40]\n",
    "def extract_train_features():\n",
    "    with h5py.File(\"/datadrive/TUH_EEG/MUPS/data/cross_sub_TUH_EEG_denoised/cross_subject_data_train_val.hdf5\") as trainValFile:\n",
    "        train_edss = (trainValFile['train_x'][()], trainValFile['train_y'][()])\n",
    "        trainCoherData = datasets.CoherenceTransformer(list(zip(train_edss[0], train_edss[1])), is_pandas=False)\n",
    "        trainSHED = datasets.SimpleHandEngineeredDataset(list(zip(train_edss[0], train_edss[1])), n_process=12, is_pandas_data=False, features=[tsf.abs_energy, tsf.kurtosis, tsf.sample_entropy, lambda x: tsf.number_cwt_peaks(x, int(constants.COMMON_FREQ/25))], f_names=[\"abs_energy\", \"kurtosis\", \"entropy\", \"num_peaks\"], vectorize=\"full\")[:]\n",
    "        train_edss = datasets.Flattener(datasets.EdfFFTDatasetTransformer(list(zip(train_edss[0], train_edss[1])), freq_bins=freq_bins, is_pandas_data=False), n_process=12)[:]\n",
    "        pkl.dump(train_edss, open(\"extracted_train_features_v2.pkl\", \"wb\"))\n",
    "extract_train_features()\n",
    "def extract_val_features():\n",
    "    with h5py.File(\"/datadrive/TUH_EEG/MUPS/data/cross_sub_TUH_EEG_denoised/cross_subject_data_train_val.hdf5\") as trainValFile:\n",
    "        train_edss = (trainValFile['val_x'][()], trainValFile['val_y'][()])\n",
    "        trainCoherData = datasets.CoherenceTransformer(list(zip(train_edss[0], train_edss[1])), is_pandas=False)\n",
    "        trainSHED = datasets.SimpleHandEngineeredDataset(list(zip(train_edss[0], train_edss[1])), n_process=12, is_pandas_data=False, features=[tsf.abs_energy, tsf.kurtosis, tsf.sample_entropy, lambda x: tsf.number_cwt_peaks(x, int(constants.COMMON_FREQ/25))], f_names=[\"abs_energy\", \"kurtosis\", \"entropy\", \"num_peaks\"], vectorize=\"full\")[:]\n",
    "        train_edss = datasets.Flattener(datasets.EdfFFTDatasetTransformer(list(zip(train_edss[0], train_edss[1])), freq_bins=freq_bins, is_pandas_data=False), n_process=12)[:]\n",
    "        pkl.dump(train_edss, open(\"extracted_val_features_v2.pkl\", \"wb\"))\n",
    "extract_val_features()\n",
    "def extract_test_features():\n",
    "    with h5py.File(\"/datadrive/TUH_EEG/MUPS/data/cross_sub_TUH_EEG_denoised/cross_subject_data_test.hdf5\") as trainValFile:\n",
    "        train_edss = (trainValFile['test_x'][()], trainValFile['test_y'][()])\n",
    "        trainCoherData = datasets.CoherenceTransformer(list(zip(train_edss[0], train_edss[1])), is_pandas=False)\n",
    "        trainSHED = datasets.SimpleHandEngineeredDataset(list(zip(train_edss[0], train_edss[1])), n_process=12, is_pandas_data=False, features=[tsf.abs_energy, tsf.kurtosis, tsf.sample_entropy, lambda x: tsf.number_cwt_peaks(x, int(constants.COMMON_FREQ/25))], f_names=[\"abs_energy\", \"kurtosis\", \"entropy\", \"num_peaks\"], vectorize=\"full\")[:]\n",
    "        train_edss = datasets.Flattener(datasets.EdfFFTDatasetTransformer(list(zip(train_edss[0], train_edss[1])), freq_bins=freq_bins, is_pandas_data=False), n_process=12)[:]\n",
    "        pkl.dump(train_edss, open(\"extracted_test_features_v2.pkl\", \"wb\"))\n",
    "extract_test_features()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "validSHED = da.SimpleHandEngineeredDataset((valid_edss), n_process=n_process, is_pandas_data=False, features=[tsf.abs_energy, tsf.sample_entropy, lambda x: tsf.number_cwt_peaks(x, int(constants.COMMON_FREQ/25))], f_names=[\"abs_energy\", \"entropy\", \"num_peaks\"], vectorize=\"full\")[:]\n",
    "testSHED = wfdata.SimpleHandEngineeredDataset((test_edss), n_process=n_process, is_pandas_data=False, features=[tsf.abs_energy, tsf.sample_entropy, lambda x: tsf.number_cwt_peaks(x, int(constants.COMMON_FREQ/25))], f_names=[\"abs_energy\", \"entropy\", \"num_peaks\"], vectorize=\"full\")[:]\n",
    "train_edss = read.Flattener(read.EdfFFTDatasetTransformer(train_edss, freq_bins=freq_bins, is_pandas_data=False), n_process=n_process)[:]\n",
    "valid_edss = read.Flattener(read.EdfFFTDatasetTransformer(valid_edss, freq_bins=freq_bins, is_pandas_data=False), n_process=n_process)[:]\n",
    "test_edss = read.Flattener(read.EdfFFTDatasetTransformer(test_edss, freq_bins=freq_bins, is_pandas_data=False), n_process=n_process)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4b2888904874>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainCoherData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoherenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_edss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_edss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_to_use\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYMMETRIC_COLUMN_SUBSET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidCoherData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoherenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_edss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_edss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_to_use\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYMMETRIC_COLUMN_SUBSET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtestCoherData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoherenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_edss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_edss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_to_use\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYMMETRIC_COLUMN_SUBSET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainSHED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimpleHandEngineeredDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_edss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_edss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_pandas_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs_energy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_cwt_peaks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMMON_FREQ\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"abs_energy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"entropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_peaks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"full\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidSHED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimpleHandEngineeredDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_edss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_edss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_process\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_pandas_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs_energy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_entropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_cwt_peaks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMMON_FREQ\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"abs_energy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"entropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_peaks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"full\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "trainCoherData = np.stack([datum.values for datum in [datum[0] for datum in wfdata.CoherenceTransformer(simple_edss(train_edss), columns_to_use=constants.SYMMETRIC_COLUMN_SUBSET, n_process=n_process, is_pandas=False)[:]]])\n",
    "validCoherData = np.stack([datum.values for datum in [datum[0] for datum in wfdata.CoherenceTransformer(simple_edss(valid_edss), columns_to_use=constants.SYMMETRIC_COLUMN_SUBSET, n_process=n_process, is_pandas=False)[:]]])\n",
    "testCoherData = np.stack([datum.values for datum in  [datum[0] for datum in wfdata.CoherenceTransformer(simple_edss(test_edss), columns_to_use=constants.SYMMETRIC_COLUMN_SUBSET, n_process=n_process, is_pandas=False)[:]]])\n",
    "trainSHED = wfdata.SimpleHandEngineeredDataset(simple_edss(train_edss), n_process=n_process, is_pandas_data=False, features=[tsf.abs_energy, tsf.sample_entropy, lambda x: tsf.number_cwt_peaks(x, int(constants.COMMON_FREQ/25))], f_names=[\"abs_energy\", \"entropy\", \"num_peaks\"], vectorize=\"full\")[:]\n",
    "validSHED = wfdata.SimpleHandEngineeredDataset(simple_edss(valid_edss), n_process=n_process, is_pandas_data=False, features=[tsf.abs_energy, tsf.sample_entropy, lambda x: tsf.number_cwt_peaks(x, int(constants.COMMON_FREQ/25))], f_names=[\"abs_energy\", \"entropy\", \"num_peaks\"], vectorize=\"full\")[:]\n",
    "testSHED = wfdata.SimpleHandEngineeredDataset(simple_edss(test_edss), n_process=n_process, is_pandas_data=False, features=[tsf.abs_energy, tsf.sample_entropy, lambda x: tsf.number_cwt_peaks(x, int(constants.COMMON_FREQ/25))], f_names=[\"abs_energy\", \"entropy\", \"num_peaks\"], vectorize=\"full\")[:]\n",
    "train_edss = read.Flattener(read.EdfFFTDatasetTransformer(train_edss, freq_bins=freq_bins, is_pandas_data=False), n_process=n_process)[:]\n",
    "valid_edss = read.Flattener(read.EdfFFTDatasetTransformer(valid_edss, freq_bins=freq_bins, is_pandas_data=False), n_process=n_process)[:]\n",
    "test_edss = read.Flattener(read.EdfFFTDatasetTransformer(test_edss, freq_bins=freq_bins, is_pandas_data=False), n_process=n_process)[:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
